{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from ps4_utils import load_data,load_experiment\n",
    "from ps4_utils import AbstractGenerativeModel\n",
    "from ps4_utils import save_submission\n",
    "from scipy.misc import logsumexp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data_fn = \"datasets-ps4.h5\"\n",
    "MAX_OUTER_ITER = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return np.log(x + np.finfo(x.dtype).eps)\n",
    "\n",
    "def confusion_matrix(Y, T):\n",
    "    M = np.zeros([T.max() + 1] * 2, dtype=np.int)\n",
    "    \n",
    "    for i, t in enumerate(T):\n",
    "        M[t, Y[i]] += 1\n",
    "        \n",
    "    assert (Y == T).sum() == M.trace()\n",
    "            \n",
    "    print(\"Confusion matrix:\")\n",
    "    plt.imshow(M, cmap=\"gray\", interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MixtureModel(AbstractGenerativeModel):\n",
    "    def __init__(self, CLASSES, NUM_FEATURES, NUM_MIXTURE_COMPONENTS, MAX_ITER=50, EPS=10**(-7)):\n",
    "        AbstractGenerativeModel.__init__(self, CLASSES, NUM_FEATURES)\n",
    "        self.num_mixture_components = NUM_MIXTURE_COMPONENTS # list of num_mixture_components (length num_classes)\n",
    "        self.max_iter = MAX_ITER # max iterations of EM\n",
    "        self.epsilon = EPS # help with stability, to be used according to hint given at end of pset4.pdf\n",
    "        self.params = { # lists of length CLASSES\n",
    "            'pi': [np.repeat(1/k,k) for k in self.num_mixture_components], # with pi_c for each class\n",
    "            'theta': [np.zeros((self.num_features,k)) for k in self.num_mixture_components], # with theta_c for each class\n",
    "        }\n",
    "    def pack_params(self, X, class_idx):\n",
    "        pi,theta = self.fit(X[class_idx],class_idx) # fit parameters\n",
    "        self.params['pi'][class_idx] = pi # update member variable pi\n",
    "        self.params['theta'][class_idx] = theta #update member variable theta\n",
    "        \n",
    "    #make classification based on which mixture model gives higher probability to generating point xi\n",
    "    def classify(self, X):\n",
    "        P = list()\n",
    "        pi = self.params['pi']\n",
    "        theta = self.params['theta']\n",
    "        for c in range(self.num_classes):\n",
    "            _,Pc = self.findP(X, pi[c], theta[c])\n",
    "            P.append(Pc)\n",
    "        return np.vstack(P).T.argmax(-1) # np.array of class predictions for each data point in X\n",
    "\n",
    "    # --- E-step\n",
    "    def updateLatentPosterior(self, X, pi, theta): # update the latent posterior\n",
    "        # YOUR CODE HERE\n",
    "        # --- gamma: np.array (matrix)\n",
    "        # ---        shape: number of data points in X (where X consists of datapoints from class c) by NUM_MIXTURE_COMPONENTS[c]\n",
    "        p, logP = self.findP(X, pi, theta)\n",
    "        return (p.T / np.e ** logP).T\n",
    "    # --- M-step (1)\n",
    "    @staticmethod\n",
    "    def updatePi(gamma): #update the pi component using the posteriors (gammas)\n",
    "        # YOUR CODE HERE\n",
    "        # --- pi_c: class specific pi, np.array (vector)\n",
    "        # ---        shape: NUM_MIXTURE_COMPONENTS[c]\n",
    "        return gamma.mean(axis=0)\n",
    "    # -- M-step (2)\n",
    "    @staticmethod\n",
    "    def updateTheta(X, gamma): #update theta component using posteriors (gammas)\n",
    "        # YOUR CODE HERE\n",
    "        # --- theta_c: class specific theta, np.array matrix\n",
    "        # ---        shape: NUM_FEATURES by NUM_MIXTURE_COMPONENTS[c]\n",
    "        return X.T.dot(gamma) / gamma.sum(axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def findP(X, pi, theta):\n",
    "        # YOUR CODE HERE\n",
    "        # --- t: probabilities of x given each component of mixture\n",
    "        # ---        shape: number of data points in X (where X consists of datapoints from class c) by NUM_MIXTURE_COMPONENTS[c] \n",
    "        # --- logsumexp(t,axis=1): normalized by factor of probabilities of x over all components of mixture\n",
    "        # ---        shape: number of data points in X (where X consists of datapoints from class c)\n",
    "        t = log(pi) + X.dot(log(theta)) + (1 - X).dot(log(1 - theta))\n",
    "        return np.e ** t, logsumexp(t, axis=1)\n",
    "        \n",
    "    # --- execute EM procedure\n",
    "    def fit(self, X, class_idx):\n",
    "        max_iter = self.max_iter\n",
    "        eps = self.epsilon\n",
    "        N = X.shape[0]\n",
    "        pi = self.params['pi'][class_idx]\n",
    "        theta = self.params['theta'][class_idx]\n",
    "        num_mixture_components = self.num_mixture_components[class_idx]\n",
    "        \n",
    "        # INITIALIZE theta\n",
    "        components = [[] for _ in range(num_mixture_components)]\n",
    "        for x in X:\n",
    "            components[np.random.randint(len(components))].append(x)\n",
    "        theta = np.array([np.array(component).mean(axis=0) for component in components]).T\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            # YOUR CODE HERE, E-step: gamma = self.updateLatentPosterior\n",
    "            gamma = self.updateLatentPosterior(X, pi, theta)\n",
    "            # YOUR CODE HERE, M-step(1): pi = self.updatePi\n",
    "            pi = self.updatePi(gamma)\n",
    "            # YOUR CODE HERE, M-step(2): theta = self.updateTheta\n",
    "            theta = np.clip(self.updateTheta(X, gamma), self.epsilon, 1 - self.epsilon)\n",
    "        return pi,theta #pi and theta, given class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayesModel(AbstractGenerativeModel):\n",
    "    def __init__(self, CLASSES, NUM_FEATURES, EPS=10**(-12)):\n",
    "        AbstractGenerativeModel.__init__(self, CLASSES, NUM_FEATURES)\n",
    "        self.epsilon = EPS # help with stability\n",
    "        self.params = {\n",
    "            'logp': [np.zeros((NUM_FEATURES))] * self.num_classes # estimated log-probabilities of features for each class\n",
    "        }\n",
    "    def pack_params(self, X, class_idx):\n",
    "        logp = self.fit(X[class_idx])\n",
    "        self.params['logp'][class_idx] = logp\n",
    "    def classify(self, X): # naive bayes classifier\n",
    "        # YOUR CODE HERE\n",
    "        # --- predictions: predictions for data points in X (where X consists of datapoints from class c), np.array (vector)\n",
    "        # ---       shape: number of data points\n",
    "        logp = np.array(self.params['logp'])\n",
    "        return (X.dot(logp.T) + (1 - X).dot(log(1 - np.e ** logp).T)).argmax(axis=1)\n",
    "    def fit(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        # --- estimated_logp: estimated logp's of features for input X (where X consists of datapoints from class c), np.array (vector)\n",
    "        # ---          shape: NUM_FEATURES\n",
    "        return log(X.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT ANALYSIS -- NAIVE BAYES MODEL:\n",
      "ACCURACY ON VALIDATION: 0.72\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((165,), 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((335,), 1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAFkCAYAAAAjYoA8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5843764e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT ANALYSIS -- MIXTURE MODEL:\n",
      "COMPONENTS: 13 13\n",
      "ACCURACY ON VALIDATION: 0.69\n",
      "COMPONENTS: 8 10\n",
      "ACCURACY ON VALIDATION: 0.718\n",
      "COMPONENTS: 5 10\n",
      "ACCURACY ON VALIDATION: 0.7\n",
      "COMPONENTS: 5 5\n",
      "ACCURACY ON VALIDATION: 0.734\n",
      "COMPONENTS: 7 11\n",
      "ACCURACY ON VALIDATION: 0.706\n",
      "COMPONENTS: 8 11\n",
      "ACCURACY ON VALIDATION: 0.744\n",
      "COMPONENTS: 12 9\n",
      "ACCURACY ON VALIDATION: 0.714\n",
      "COMPONENTS: 8 13\n",
      "ACCURACY ON VALIDATION: 0.704\n",
      "COMPONENTS: 7 8\n",
      "ACCURACY ON VALIDATION: 0.724\n",
      "COMPONENTS: 11 6\n",
      "ACCURACY ON VALIDATION: 0.734\n",
      "COMPONENTS: 6 14\n",
      "ACCURACY ON VALIDATION: 0.696\n",
      "COMPONENTS: 8 12\n",
      "ACCURACY ON VALIDATION: 0.71\n",
      "COMPONENTS: 9 11\n",
      "ACCURACY ON VALIDATION: 0.726\n",
      "COMPONENTS: 5 6\n",
      "ACCURACY ON VALIDATION: 0.738\n",
      "COMPONENTS: 5 5\n",
      "ACCURACY ON VALIDATION: 0.704\n",
      "BEST ACCURACY: 0.744\n",
      "Saved: mm-sentiment_analysis-submission.csv\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"sentiment_analysis\"\n",
    "# --- SENTIMENT ANALYSIS setup\n",
    "Xtrain,Xval,num_classes,num_features = load_experiment(data_fn, experiment_name)\n",
    "\n",
    "# -- build naive bayes model for sentiment analysis\n",
    "print(\"SENTIMENT ANALYSIS -- NAIVE BAYES MODEL:\")\n",
    "nbm = NaiveBayesModel(num_classes, num_features)\n",
    "nbm.train(Xtrain)\n",
    "print(\"ACCURACY ON VALIDATION: \" + str(nbm.val(Xval)))\n",
    "\n",
    "Y = np.array([])\n",
    "T = np.array([])\n",
    "\n",
    "for c in range(num_classes):\n",
    "    Yc = nbm.classify(Xval[c])\n",
    "    Y = np.concatenate((Y, Yc))\n",
    "    T = np.concatenate((T, np.full(Yc.shape, c)))\n",
    "\n",
    "assert Y.shape == T.shape\n",
    "confusion_matrix(Y, T)\n",
    "\n",
    "# -- build mixture model for sentiment analysis\n",
    "print(\"SENTIMENT ANALYSIS -- MIXTURE MODEL:\")\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = None\n",
    "\n",
    "for i in range(MAX_OUTER_ITER):\n",
    "    num_mixture_components =  np.random.randint(5,15,num_classes)\n",
    "    print(\"COMPONENTS: \" + \" \".join(str(i) for i in num_mixture_components))\n",
    "    mm = MixtureModel(num_classes, num_features, num_mixture_components)\n",
    "    mm.train(Xtrain)\n",
    "    accuracy = mm.val(Xval)\n",
    "    print(\"ACCURACY ON VALIDATION:\", accuracy)\n",
    "    \n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = mm\n",
    "\n",
    "print(\"BEST ACCURACY:\", best_accuracy)\n",
    "\n",
    "# submit to kaggle\n",
    "Xkaggle = load_data(data_fn, experiment_name, \"kaggle\")\n",
    "save_submission(\"mm-{}-submission.csv\".format(experiment_name), best_model.classify(Xkaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST DIGIT CLASSIFICATION -- NAIVE BAYES MODEL:\n",
      "ACCURACY ON VALIDATION: 0.733\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((187,), 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((223,), 1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((210,), 2) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((183,), 3) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((193,), 4) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((172,), 5) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((217,), 6) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((233,), 7) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((196,), 8) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((186,), 9) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/raviqqe/.local/lib/python3.5/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAFdCAYAAABGoXXzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5842d6ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST DIGIT CLASSIFICATION -- MIXTURE MODEL:\n",
      "COMPONENTS: 13 10 13 6 8 14 12 10 11 5\n",
      "ACCURACY ON VALIDATION: 0.7745\n",
      "COMPONENTS: 14 8 5 6 12 14 14 5 6 9\n",
      "ACCURACY ON VALIDATION: 0.7895\n",
      "COMPONENTS: 12 13 6 7 8 13 14 14 10 7\n",
      "ACCURACY ON VALIDATION: 0.7745\n",
      "COMPONENTS: 7 12 8 8 7 14 13 10 12 6\n",
      "ACCURACY ON VALIDATION: 0.769\n",
      "COMPONENTS: 11 6 7 9 12 8 5 13 5 9\n",
      "ACCURACY ON VALIDATION: 0.7845\n",
      "COMPONENTS: 7 8 14 10 13 9 14 12 6 13\n",
      "ACCURACY ON VALIDATION: 0.7815\n",
      "COMPONENTS: 9 6 8 5 9 8 12 12 9 12\n",
      "ACCURACY ON VALIDATION: 0.7805\n",
      "COMPONENTS: 13 13 6 9 9 11 6 6 14 6\n",
      "ACCURACY ON VALIDATION: 0.785\n",
      "COMPONENTS: 11 5 11 6 8 8 5 6 7 5\n",
      "ACCURACY ON VALIDATION: 0.7965\n",
      "COMPONENTS: 12 8 5 12 14 5 14 8 11 9\n",
      "ACCURACY ON VALIDATION: 0.798\n",
      "COMPONENTS: 11 6 8 14 5 10 9 14 11 13\n",
      "ACCURACY ON VALIDATION: 0.7835\n",
      "COMPONENTS: 7 9 13 7 8 6 8 14 5 11\n",
      "ACCURACY ON VALIDATION: 0.786\n",
      "COMPONENTS: 7 6 12 7 8 10 8 9 11 5\n",
      "ACCURACY ON VALIDATION: 0.7845\n",
      "COMPONENTS: 13 10 9 6 12 5 14 14 5 12\n",
      "ACCURACY ON VALIDATION: 0.7815\n",
      "COMPONENTS: 6 12 9 13 9 11 6 14 8 13\n",
      "ACCURACY ON VALIDATION: 0.781\n",
      "BEST ACCURACY: 0.798\n",
      "Saved: mm-mnist-submission.csv\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"mnist\"\n",
    "# --- MNIST DIGIT CLASSIFICATION setup\n",
    "Xtrain,Xval,num_classes,num_features = load_experiment(data_fn, experiment_name)\n",
    "\n",
    "# -- build naive bayes model for mnist digit classification\n",
    "print(\"MNIST DIGIT CLASSIFICATION -- NAIVE BAYES MODEL:\")\n",
    "nbm = NaiveBayesModel(num_classes, num_features)\n",
    "nbm.train(Xtrain)\n",
    "print(\"ACCURACY ON VALIDATION: \" + str(nbm.val(Xval)))\n",
    "\n",
    "Y = np.array([])\n",
    "T = np.array([])\n",
    "\n",
    "for c in range(num_classes):\n",
    "    Yc = nbm.classify(Xval[c])\n",
    "    Y = np.concatenate((Y, Yc))\n",
    "    T = np.concatenate((T, np.full(Yc.shape, c)))\n",
    "\n",
    "confusion_matrix(Y, T)\n",
    "\n",
    "# -- build mixture model for mnist digit classification\n",
    "print(\"MNIST DIGIT CLASSIFICATION -- MIXTURE MODEL:\")\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = None\n",
    "\n",
    "for i in range(MAX_OUTER_ITER):\n",
    "    num_mixture_components =  np.random.randint(5,15,num_classes)\n",
    "    print(\"COMPONENTS: \" + \" \".join(str(i) for i in num_mixture_components))\n",
    "    mm = MixtureModel(num_classes, num_features, num_mixture_components)\n",
    "    mm.train(Xtrain)\n",
    "    accuracy = mm.val(Xval)\n",
    "    print(\"ACCURACY ON VALIDATION:\", accuracy)\n",
    "    \n",
    "    if best_accuracy is None or accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = mm\n",
    "\n",
    "print(\"BEST ACCURACY:\", best_accuracy)\n",
    "\n",
    "# submit to kaggle\n",
    "Xkaggle = load_data(data_fn, experiment_name, \"kaggle\")\n",
    "save_submission(\"mm-{}-submission.csv\".format(experiment_name), best_model.classify(Xkaggle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
